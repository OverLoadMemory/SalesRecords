# -*- coding: utf-8 -*-
"""Attestation3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FhBaEBCGCGO1K9WkcZmDQdgbfrWHp6dV

**Задача**   

---

Проведите кластеризацию стран по показателям заболеваемости, смертности и выздоровлений за прошедшие сутки. Визуализируйте результаты. Сколько получилось кластеров? Где оказалась Россия? Сделайте выводы. Проведите аналогичный анализ для каждого из 12 предыдущих месяцев. Есть ли различие в кластерах? Если есть, то как его можно объяснить?

# **Критерии оценки**

---
Кейс оценивается суммой баллов, получаемых согласно следующим критериям:

Проработка бизнес-задачи проекта (проблематика проекта) — 3 балла;

Понимание данных — 3 балла;

Подготовка данных — 3 балла;

Моделирование — 3 балла;

Оценка — 3 балла;

Развёртывание - 3 балла.

**Проходной балл - 9 баллов.**

**Устанавливаем библиотеки (при необходимости)**
"""

!pip install matplotlib
!pip install pandas
!pip install numpy
!pip install unzip

"""**Загрузка пакета данных с GitHub**

Можно загружать базы данных из любых источников, в том числе и локальных. Необходимо будет поменять код модуля загрузки данных.


"""

import urllib.request
urllib.request.urlretrieve('https://github.com/OverLoadMemory/SalesRecords/archive/master.zip','master.zip')
!unzip master.zip

!unzip '/content/SalesRecords-main/SalesRecords.zip'

"""**Изучаем состав данных в ZIP файле.**"""

import pandas as pd
df = pd.read_csv("/content/content/SalesRecords.csv", sep=",", encoding='UTF-8', )
#df1 = df.set_index('Country', inplace=True)
df

"""**Проверим, есть ли необходимость сгуппировать данные.**"""

Item_Type = ['Clothes']
df1 = df[df['Item Type'].isin(Item_Type)]

df1

"""**Выбираем и выгружаем данные.**

В данном модуле мы можем отобрать интересующие нас товара и провести анализ данных только по ним. К примеру, стоит задача определить наиболее перспективные регионы для продажи одежды [ Clothes ]. Что позволит сократить издержки на неперспективных направлениях или проанализировать, почему в по этим направлениям одежда хуже продается, проведя более глубокий анализ по стилю, фасону или ценовой категории одежды.
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from datetime import datetime
from dateutil.relativedelta import relativedelta

#    Зададим переменную по группе товара
Item_Type = input('Введите название интересующей вас группы товаров:    ')
#Item_Type = list(Item_Type)
df = df[df['Item Type'].isin([Item_Type])]
#    Остави только интересующие нас данные
df1 = df[['Country', 'Item Type', 'Units Sold', 'Total Revenue', 'Total Profit']].fillna (0)
#    Суммируем показатели по каждой стране и назначаем уникальные названия переменных
df1 = df1.groupby('Country', as_index = False)[['Item Type', 'Units Sold', 'Total Revenue', 'Total Profit']].sum()
df1 = df1.sort_values(by='Units Sold', ascending=False)

df1

"""**Возьмем группу покупателей, которы приобрели больше 136000 единиц одежды.**"""

df2 = df1[df1['Units Sold'] > 136000][['Country','Units Sold', 'Total Profit']]
df2.set_index('Country', inplace=True)
df2.index.name = None
df2.columns.name = 'Country'
df2

df2.columns

"""**Проверим данные**"""

fig, ax = plt.subplots(figsize=(86, 24))
#

ax.bar(df2.index, df2['Units Sold'], color='g')

ax.set_xlabel('Страны', fontsize=32)
ax.set_ylabel('Количество проданных шт.', fontsize=48)
ax.set_title('Показатели', fontsize=32)
plt.xticks(rotation=90, fontsize=48)

plt.show()

"""**Определимся с выбором кластеризации** 

---


**Определяем количество кластеров**

*По методу построения Дендрограммы.*
"""

from scipy.cluster.hierarchy import dendrogram, linkage
linkage_matrix = linkage(df2, method='ward')
dendrogram = dendrogram(linkage_matrix, labels=df2.index, orientation='top', leaf_font_size=10)
plt.title('Dendrogram')
plt.xlabel('Samples')
plt.ylabel('Distance')
plt.xticks(rotation=90, fontsize=6)
plt.show()

"""*Метод локтя и коэффициента силуэта.*

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Выберите столбцы, которые вы хотите использовать для анализа
X = df2[['Units Sold', 'Total Profit']]

# Определите оптимальное количество кластеров методом локтя
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)
plt.plot(range(1, 11), wcss)
plt.title('Метод локтя')
plt.xlabel('Количество кластеров')
plt.ylabel('WCSS')
plt.show()

# Определите оптимальное количество кластеров методом коэффициента силуэта
sil = []
for k in range(2, 11):
  kmeans = KMeans(n_clusters = k).fit(X)
  labels = kmeans.labels_
  sil.append(silhouette_score(X, labels, metric = 'euclidean'))
plt.plot(range(2, 11), sil)
plt.title('Коэффициент силуэта')
plt.xlabel('Количество кластеров')
plt.ylabel('Silhouette Score')
plt.show()

"""**По приведенным выше методам определения количества кластеров делаем вывод, что оптимальное количество кластеров 3.**

*Метод иерархической кластеризации.*
"""

from scipy.spatial.distance import pdist, squareform
from scipy.cluster.hierarchy import linkage, dendrogram
import matplotlib.pyplot as plt


# вычисление евклидова расстояния между строками
distances = pdist(df2.values, metric='euclidean')

# преобразование расстояний в квадратную матрицу
sq_distances = squareform(distances)

# иерархическая кластеризация методом взвешенного среднего объединения
linkage_matrix = linkage(sq_distances, method='ward')

# построение дендрограммы
dendrogram(linkage_matrix, labels=df2.index, orientation='top', leaf_font_size=10)

plt.ylabel('Euclidean Distance')
plt.title('Hierarchical Clustering Dendrogram')
plt.xticks(rotation=90, fontsize=16)
plt.show()

"""**Дендограмма, по моему мнению, показала наиболее точный результат распределения по группам. Таким образом проведя анализ всех подгрупп товаров, можно найти пересечения и выявить максимально продуктивные и безпроблемные направления. По отстающим группам, как в явном виде, так и по пересечениям, необходимо провести дополнительный анализ, разместить больше актуальной рекламы, подключить СММ к продвижению, залежашегося на складах товаров. При этом, можно сократить расходы на рекламу в странах с большим уровнем продаж. Также необходимо провести анализ по актуальности конкретных товаров в подгруппах для конкретной страны, возможно надо сменить ассортимент. Также, необходимо провести анализ доходов в отставших странах и выбрать более доступные товары в подгруппах.**"""